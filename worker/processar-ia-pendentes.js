// Script para processar IA (Gemini) de pesquisas pendentes
// TambÃ©m transcreve Ã¡udios quando necessÃ¡rio antes de processar com IA

import dotenv from 'dotenv';
dotenv.config({ override: true });
import { supabaseAdmin } from './supabaseAdminClient.js';
import OpenAI from 'openai';
import os from 'os';
import fs from 'fs/promises';
import { createReadStream } from 'fs';
import path from 'path';

const geminiApiKey = process.env.GEMINI_API_KEY;
const openaiApiKey = process.env.OPENAI_API_KEY;
const STT_PROVIDER = process.env.STT_PROVIDER || 'openai';
const BATCH_SIZE = parseInt(process.env.IA_BATCH_SIZE || '5', 10);

const client = openaiApiKey ? new OpenAI({ apiKey: openaiApiKey }) : null;

if (!geminiApiKey) {
  console.error('GEMINI_API_KEY nÃ£o definido. Saindo.');
  process.exit(1);
}

// ============ FunÃ§Ãµes de TranscriÃ§Ã£o ============
async function downloadToTemp(url, nameHint = 'audio.webm') {
  const res = await fetch(url);
  if (!res.ok) throw new Error(`Falha ao baixar Ã¡udio: ${res.status} ${res.statusText}`);
  const buf = Buffer.from(await res.arrayBuffer());
  const tmp = path.join(os.tmpdir(), `${Date.now()}_${nameHint}`);
  await fs.writeFile(tmp, buf);
  return tmp;
}

async function transcribeWithOpenAI(filePath) {
  if (!client) throw new Error('OPENAI_API_KEY ausente');
  const readStream = createReadStream(filePath);
  const transcription = await client.audio.transcriptions.create({
    file: readStream,
    model: 'whisper-1',
    language: 'pt',
  });
  return transcription.text || '';
}

async function transcreverComGemini(audioUrl) {
  // Gemini pode transcrever Ã¡udio diretamente
  if (!geminiApiKey) {
    throw new Error('GEMINI_API_KEY nÃ£o definido para transcriÃ§Ã£o');
  }
  
  // Baixar Ã¡udio e converter para base64
  const res = await fetch(audioUrl);
  if (!res.ok) throw new Error(`Falha ao baixar Ã¡udio: ${res.status}`);
  const audioBuffer = await res.arrayBuffer();
  const audioBase64 = Buffer.from(audioBuffer).toString('base64');
  
  // Usar Gemini 2.5 Flash para transcriÃ§Ã£o
  const model = 'gemini-2.5-flash';
  const url = `https://generativelanguage.googleapis.com/v1/models/${model}:generateContent`;
  
  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-goog-api-key': geminiApiKey,
    },
    body: JSON.stringify({
      contents: [{
        parts: [{
          inline_data: {
            mime_type: 'audio/webm',
            data: audioBase64
          }
        }, {
          text: 'Transcreva este Ã¡udio em portuguÃªs brasileiro. Retorne apenas o texto transcrito, sem explicaÃ§Ãµes.'
        }]
      }]
    })
  });
  
  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Gemini transcriÃ§Ã£o falhou: ${response.status} - ${errorText}`);
  }
  
  const data = await response.json();
  const texto = data?.candidates?.[0]?.content?.parts?.[0]?.text;
  if (!texto) throw new Error('Gemini nÃ£o retornou transcriÃ§Ã£o');
  
  return texto.trim();
}

async function transcreverComAPILocal(audioUrl) {
  // Usa API local de Whisper (gratuita, sem quota)
  const apiUrl = process.env.TRANSCRIPTION_API_URL || 'http://localhost:3004/api/transcribe';
  
  const res = await fetch(apiUrl, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ audio_url: audioUrl })
  });
  
  if (!res.ok) {
    const error = await res.text();
    throw new Error(`API local falhou: ${res.status} - ${error}`);
  }
  
  const data = await res.json();
  if (!data.success || !data.texto) {
    throw new Error(`API local retornou erro: ${data.error || 'Sem texto'}`);
  }
  
  return data.texto;
}

async function transcreverAudio(audioUrl) {
  if (!audioUrl) throw new Error('URL do Ã¡udio nÃ£o fornecida');
  
  // LÃ³gica de fallback inteligente: tenta provider configurado, depois o outro automaticamente
  if (STT_PROVIDER === 'gemini') {
    // Tentar Gemini primeiro
    if (geminiApiKey) {
      try {
        console.log('ðŸŽ¤ Tentando transcriÃ§Ã£o com Gemini...');
        return await transcreverComGemini(audioUrl);
      } catch (e) {
        console.warn(`âš ï¸ Gemini falhou: ${e.message}`);
        // Fallback automÃ¡tico para OpenAI se disponÃ­vel
        if (openaiApiKey) {
          console.log('ðŸ”„ Tentando fallback para OpenAI...');
          const tmpFile = await downloadToTemp(audioUrl, `transcribe_${Date.now()}.webm`);
          try {
            return await transcribeWithOpenAI(tmpFile);
          } finally {
            try { await fs.unlink(tmpFile); } catch {}
          }
        }
        throw e; // Se nÃ£o houver fallback, lanÃ§a o erro
      }
    } else if (openaiApiKey) {
      // Se Gemini nÃ£o configurado mas OpenAI sim, usar OpenAI
      console.log('âš ï¸ Gemini nÃ£o configurado, usando OpenAI...');
      const tmpFile = await downloadToTemp(audioUrl, `transcribe_${Date.now()}.webm`);
      try {
        return await transcribeWithOpenAI(tmpFile);
      } finally {
        try { await fs.unlink(tmpFile); } catch {}
      }
    } else {
      throw new Error('Nem GEMINI_API_KEY nem OPENAI_API_KEY estÃ£o configurados');
    }
  } else if (STT_PROVIDER === 'openai') {
    // Tentar OpenAI primeiro
    if (openaiApiKey) {
      try {
        const tmpFile = await downloadToTemp(audioUrl, `transcribe_${Date.now()}.webm`);
        try {
          return await transcribeWithOpenAI(tmpFile);
        } finally {
          try { await fs.unlink(tmpFile); } catch {}
        }
      } catch (e) {
        console.warn(`âš ï¸ OpenAI falhou: ${e.message}`);
        // Fallback automÃ¡tico para Gemini se disponÃ­vel
        if (geminiApiKey) {
          console.log('ðŸ”„ Tentando fallback para Gemini...');
          return await transcreverComGemini(audioUrl);
        }
        throw e; // Se nÃ£o houver fallback, lanÃ§a o erro
      }
    } else if (geminiApiKey) {
      // Se OpenAI nÃ£o configurado mas Gemini sim, usar Gemini
      console.log('âš ï¸ OpenAI nÃ£o configurado, usando Gemini...');
      return await transcreverComGemini(audioUrl);
    } else {
      throw new Error('Nem OPENAI_API_KEY nem GEMINI_API_KEY estÃ£o configurados');
    }
  } else if (STT_PROVIDER === 'local') {
    // Usa API local de Whisper (gratuita)
    return await transcreverComAPILocal(audioUrl);
  } else {
    throw new Error(`STT_PROVIDER nÃ£o suportado: ${STT_PROVIDER}. Use 'openai', 'gemini' ou 'local'`);
  }
}

async function atualizarTranscricao(pesquisaId, transcricao) {
  const { error } = await supabaseAdmin
    .from('pesquisas')
    .update({
      transcricao_completa: transcricao,
      stt_status: 'concluido',
      stt_erro: null,
    })
    .eq('id', pesquisaId);
  if (error) throw error;
}

// ============ FunÃ§Ãµes de IA ============
async function listGeminiModels() {
  if (!geminiApiKey) return [];
  const url = `https://generativelanguage.googleapis.com/v1/models?key=${geminiApiKey}`;
  try {
    const res = await fetch(url);
    if (!res.ok) return [];
    const data = await res.json();
    return (data?.models || []).map((m) => m.name).filter(Boolean);
  } catch {
    return [];
  }
}

function scoreModelId(id) {
  const s = String(id).toLowerCase();
  let score = 0;
  if (s.includes('flash')) score += 50;
  if (s.includes('pro')) score += 30;
  if (/(^|[-])2\.5(\.|$)/.test(s)) score += 40; // preferir 2.5
  else if (/(^|[-])2(\.|$)/.test(s)) score += 30; // demais 2.x
  else if (/(^|[-])1\.5($|[-])/.test(s)) score += 10;
  if (s.endsWith('latest')) score += 5;
  return score;
}

async function resolveGeminiModel() {
  if (!geminiApiKey) throw new Error('GEMINI_API_KEY nÃ£o definido');
  try {
    const names = await listGeminiModels(); // ex.: ["models/gemini-2.5-flash", ...]
    const ids = names.map((n) => (typeof n === 'string' ? n.split('/').pop() || n : n));
    ids.sort((a, b) => scoreModelId(b) - scoreModelId(a));
    const best = ids[0];
    if (best) {
      console.log(`âœ“ Modelo Gemini selecionado: ${best}`);
      return best;
    }
    } catch (e) {
    console.warn('Erro ao listar modelos Gemini:', e?.message || e);
    }
  // fallback estÃ¡tico
  console.log('Usando modelo fallback: gemini-2.5-flash');
  return 'gemini-2.5-flash';
}

function montarPrompt(transcricao, campos, candidato) {
  const listaCampos = (campos || [])
    .map((campo) => {
      let desc = `- ${campo.id} (${campo.tipo})`;
      if (campo.label) desc += `: "${campo.label}"`;
      if (Array.isArray(campo.opcoes) && campo.opcoes.length > 0) {
        desc += ` | OpÃ§Ãµes: ${campo.opcoes.join(', ')}`;
      }
      return desc;
    })
    .join('\n');

  return `VocÃª Ã© um assistente que extrai dados estruturados de transcriÃ§Ãµes de entrevistas de pesquisa eleitoral.

**Candidato:** ${candidato || 'NÃ£o especificado'}

**Campos do formulÃ¡rio:**
${listaCampos}

**TranscriÃ§Ã£o da entrevista:**
${transcricao}

**InstruÃ§Ãµes:**
1. Leia a transcriÃ§Ã£o e identifique as respostas para cada campo
2. Para campos com opÃ§Ãµes, escolha APENAS uma das opÃ§Ãµes listadas (case-insensitive)
3. Para campos de texto livre, extraia a resposta literal
4. Se nÃ£o houver resposta clara, use null
5. Retorne APENAS um JSON vÃ¡lido no formato: { "campo_id": "valor", ... }
6. NÃ£o adicione explicaÃ§Ãµes, apenas o JSON

**Responda agora com o JSON:**`;
}

async function processarIAComGemini(transcricao, campos, candidato, modelName) {
  if (!geminiApiKey) throw new Error('GEMINI_API_KEY ausente');
  const mdl = modelName || 'gemini-2.5-flash';
  const url = `https://generativelanguage.googleapis.com/v1/models/${encodeURIComponent(mdl)}:generateContent`;
  
  const prompt = montarPrompt(transcricao, campos, candidato);
  
  const res = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-goog-api-key': geminiApiKey,
    },
    body: JSON.stringify({
      contents: [{ role: 'user', parts: [{ text: prompt }] }]
    })
  });
  
  if (!res.ok) {
    const text = await res.text();
    throw new Error(`Gemini HTTP ${res.status}: ${text}`);
  }
  
  const data = await res.json();
  const texto = data?.candidates?.[0]?.content?.parts?.[0]?.text;
  if (!texto) throw new Error('Resposta do Gemini sem texto');
  
  let json = String(texto).trim();
  if (json.startsWith('```')) {
    json = json.replace(/```json\s*/g, '').replace(/```\s*$/g, '');
  }
  
  const jsonMatch = json.match(/\{[\s\S]*\}/);
  if (!jsonMatch) throw new Error('IA nÃ£o retornou JSON vÃ¡lido');
  
  return JSON.parse(jsonMatch[0]);
}

async function fetchPesquisa(pesquisaId) {
  const { data, error } = await supabaseAdmin
    .from('pesquisas')
    .select('id, formulario_id, respostas, transcricao_completa, audio_url, stt_status, stt_erro')
    .eq('id', pesquisaId)
    .single();
  if (error) throw error;
  return data;
}

async function fetchFormulario(formularioId) {
  if (!formularioId) return null;
  const { data, error } = await supabaseAdmin
    .from('formularios')
    .select('id, nome, pre_candidato, campos')
    .eq('id', formularioId)
    .single();
  if (error) throw error;
  return data;
}

async function updatePesquisaIA(pesquisaId, respostasIA) {
  const { error } = await supabaseAdmin
    .from('pesquisas')
    .update({
      respostas_ia: respostasIA,
      processamento_ia_status: 'concluido',
      observacoes_ia: null  // Limpar observaÃ§Ãµes de erro anteriores quando processa com sucesso
    })
    .eq('id', pesquisaId);
  if (error) throw error;
}

async function markPesquisaIAErro(pesquisaId, erro) {
  const { error } = await supabaseAdmin
    .from('pesquisas')
    .update({
      processamento_ia_status: 'erro',
      observacoes_ia: erro
    })
    .eq('id', pesquisaId);
  if (error) throw error;
}

async function fetchPesquisasPendentes(limit) {
  // Buscar pesquisas criadas em 16-11-2025 que tenham Ã¡udios
  // Essas pesquisas serÃ£o retranscritas e reprocessadas
  // Usa criado_em (data de criaÃ§Ã£o no banco) ao invÃ©s de iniciada_em
  const dataInicio = '2025-11-16T00:00:00.000Z';
  const dataFim = '2025-11-16T23:59:59.999Z';
  
  const { data, error } = await supabaseAdmin
    .from('pesquisas')
    .select('id, transcricao_completa, audio_url, formulario_id, stt_status, stt_erro, processamento_ia_status, criado_em')
    .not('audio_url', 'is', null)
    .gte('criado_em', dataInicio)
    .lte('criado_em', dataFim)
    .order('criado_em', { ascending: true })
    .limit(limit);
  if (error) {
    console.error('Erro ao buscar pesquisas:', error);
    throw error;
  }
  console.log(`Query executada: pesquisas criadas entre ${dataInicio} e ${dataFim} com audio_url nÃ£o nulo`);
  return data || [];
}

async function processar(pesquisa, modelName) {
  try {
    console.log(`Processando pesquisa ${pesquisa.id} (erro anterior: ${pesquisa.stt_erro || 'N/A'})...`);
    
    const pesquisaCompleta = await fetchPesquisa(pesquisa.id);
    const formulario = await fetchFormulario(pesquisaCompleta.formulario_id);
    
    if (!formulario || !formulario.campos) {
      console.log(`Pesquisa ${pesquisa.id}: sem formulÃ¡rio ou campos`);
      return;
    }
    
    if (!pesquisaCompleta.audio_url) {
      console.log(`Pesquisa ${pesquisa.id}: sem Ã¡udio. Pulando.`);
      return;
    }
    
    // SEMPRE retranscrever o Ã¡udio (mesmo que jÃ¡ exista transcriÃ§Ã£o)
    console.log(`ðŸ“ Retranscrevendo Ã¡udio da pesquisa ${pesquisa.id}...`);
    let transcricao;
    try {
      // Atualizar status para processando e limpar erro anterior
      await supabaseAdmin
        .from('pesquisas')
        .update({ stt_status: 'processando', stt_erro: null })
        .eq('id', pesquisa.id);
      
      transcricao = await transcreverAudio(pesquisaCompleta.audio_url);
      await atualizarTranscricao(pesquisa.id, transcricao);
      console.log(`âœ“ TranscriÃ§Ã£o concluÃ­da para pesquisa ${pesquisa.id}`);
    } catch (e) {
      const msg = e?.message || String(e);
      console.error(`âœ— Erro na transcriÃ§Ã£o da pesquisa ${pesquisa.id}:`, msg);
      await supabaseAdmin
        .from('pesquisas')
        .update({ stt_status: 'erro', stt_erro: msg })
        .eq('id', pesquisa.id);
      throw new Error(`Falha na transcriÃ§Ã£o: ${msg}`);
    }
    
    // Processar com IA
    console.log(`ðŸ¤– Processando IA para pesquisa ${pesquisa.id}...`);
    const respostasIA = await processarIAComGemini(
      transcricao,
      formulario.campos,
      formulario.pre_candidato,
      modelName
    );
    
    await updatePesquisaIA(pesquisa.id, respostasIA);
    console.log(`âœ“ Pesquisa ${pesquisa.id} processada com sucesso`);
    
  } catch (e) {
    const msg = e?.message || String(e);
    console.error(`âœ— Erro na pesquisa ${pesquisa.id}:`, msg);
    await markPesquisaIAErro(pesquisa.id, msg);
  }
}

async function main() {
  console.log('Processador de IA iniciado...');
  console.log('Este worker reprocessa pesquisas criadas em 16-11-2025 que tenham Ã¡udios.');
  console.log('Retranscreve os Ã¡udios e processa com IA.');
  
  // Verificar configuraÃ§Ã£o de transcriÃ§Ã£o
  if (STT_PROVIDER === 'gemini') {
    if (!geminiApiKey) {
      console.error('âŒ GEMINI_API_KEY nÃ£o definido. TranscriÃ§Ã£o com Gemini nÃ£o serÃ¡ possÃ­vel.');
      if (!openaiApiKey) {
        console.error('âŒ OPENAI_API_KEY tambÃ©m nÃ£o definido. Saindo.');
        process.exit(1);
      }
      console.log('âš ï¸ Usando OpenAI como fallback...');
    } else {
      console.log('ðŸŽ¤ TranscriÃ§Ã£o: Gemini (com fallback para OpenAI se necessÃ¡rio)');
    }
  } else if (STT_PROVIDER === 'openai') {
    if (!openaiApiKey) {
      console.error('âŒ OPENAI_API_KEY nÃ£o definido.');
      if (geminiApiKey) {
        console.log('âš ï¸ Usando Gemini como fallback...');
      } else {
        console.error('âŒ GEMINI_API_KEY tambÃ©m nÃ£o definido. Saindo.');
        process.exit(1);
      }
    } else {
      console.log('ðŸŽ¤ TranscriÃ§Ã£o: OpenAI');
    }
  } else if (STT_PROVIDER === 'local') {
    const apiUrl = process.env.TRANSCRIPTION_API_URL || 'http://localhost:3004/api/transcribe';
    console.log(`ðŸ“¡ Usando API local de Whisper: ${apiUrl}`);
    console.log('ðŸ’¡ Certifique-se de que a API local estÃ¡ rodando (npm start na pasta api/)');
  }
  
  // Resolver modelo Gemini
  const modelName = await resolveGeminiModel();
  console.log('Modelo Gemini selecionado:', modelName);
  
  let totalProcessadas = 0;
  let rodada = 1;
  
  // Verificar quantas pesquisas existem antes de processar
  const { count } = await supabaseAdmin
    .from('pesquisas')
    .select('*', { count: 'exact', head: true })
    .not('audio_url', 'is', null)
    .gte('criado_em', '2025-11-16T00:00:00.000Z')
    .lte('criado_em', '2025-11-16T23:59:59.999Z');
  console.log(`\nðŸ“Š Total de pesquisas de 16-11-2025 com Ã¡udios no banco: ${count || 0}`);
  
  // Loop atÃ© processar todas
  while (true) {
    console.log(`\n--- Rodada ${rodada} ---`);
    
    // Buscar pesquisas criadas em 16-11-2025 com Ã¡udios
    const pesquisas = await fetchPesquisasPendentes(BATCH_SIZE);
    console.log(`Encontradas ${pesquisas.length} pesquisas de 16-11-2025 com Ã¡udios`);
    
    if (pesquisas.length === 0) {
      console.log('\nâœ“ Todas as pesquisas de 16-11-2025 foram reprocessadas!');
      console.log(`Total processado: ${totalProcessadas} pesquisas`);
      break;
    }
    
    // Processar em lote
    for (const pesquisa of pesquisas) {
      await processar(pesquisa, modelName);
      totalProcessadas++;
    }
    
    console.log(`Processadas ${pesquisas.length} pesquisas nesta rodada`);
    rodada++;
    
    // Pequeno delay entre rodadas para nÃ£o sobrecarregar
    await new Promise(resolve => setTimeout(resolve, 1000));
  }
  
  console.log('\nProcessamento concluÃ­do!');
}

main().catch(err => {
  console.error('Erro fatal:', err);
  process.exit(1);
});

