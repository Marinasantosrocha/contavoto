// Worker para transcrever apenas pesquisas pendentes
// Processa 5 pesquisas por vez: criadas em 16-11-2025, com Ã¡udio, sem resposta de IA

import dotenv from 'dotenv';
dotenv.config({ override: true });
import { supabaseAdmin } from './supabaseAdminClient.js';
import OpenAI from 'openai';
import os from 'os';
import fs from 'fs/promises';
import { createReadStream } from 'fs';
import path from 'path';

const geminiApiKey = process.env.GEMINI_API_KEY;
const openaiApiKey = process.env.OPENAI_API_KEY;
const STT_PROVIDER = process.env.STT_PROVIDER || 'openai';
const BATCH_SIZE = 5; // Fixo: sempre 5 pesquisas

const client = openaiApiKey ? new OpenAI({ apiKey: openaiApiKey }) : null;

// ============ FunÃ§Ãµes de TranscriÃ§Ã£o ============
async function downloadToTemp(url, nameHint = 'audio.webm') {
  const res = await fetch(url);
  if (!res.ok) throw new Error(`Falha ao baixar Ã¡udio: ${res.status} ${res.statusText}`);
  const buf = Buffer.from(await res.arrayBuffer());
  const tmp = path.join(os.tmpdir(), `${Date.now()}_${nameHint}`);
  await fs.writeFile(tmp, buf);
  return tmp;
}

async function transcribeWithOpenAI(filePath) {
  if (!client) throw new Error('OPENAI_API_KEY ausente');
  const readStream = createReadStream(filePath);
  const transcription = await client.audio.transcriptions.create({
    file: readStream,
    model: 'whisper-1',
    language: 'pt',
  });
  return transcription.text || '';
}

async function transcreverComGemini(audioUrl) {
  if (!geminiApiKey) {
    throw new Error('GEMINI_API_KEY nÃ£o definido para transcriÃ§Ã£o');
  }
  
  const res = await fetch(audioUrl);
  if (!res.ok) throw new Error(`Falha ao baixar Ã¡udio: ${res.status}`);
  const audioBuffer = await res.arrayBuffer();
  const audioBase64 = Buffer.from(audioBuffer).toString('base64');
  
  const model = 'gemini-2.5-flash';
  const url = `https://generativelanguage.googleapis.com/v1/models/${model}:generateContent`;
  
  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-goog-api-key': geminiApiKey,
    },
    body: JSON.stringify({
      contents: [{
        parts: [{
          inline_data: {
            mime_type: 'audio/webm',
            data: audioBase64
          }
        }, {
          text: 'Transcreva este Ã¡udio em portuguÃªs brasileiro. Retorne apenas o texto transcrito, sem explicaÃ§Ãµes.'
        }]
      }]
    })
  });
  
  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Gemini transcriÃ§Ã£o falhou: ${response.status} - ${errorText}`);
  }
  
  const data = await response.json();
  const texto = data?.candidates?.[0]?.content?.parts?.[0]?.text;
  if (!texto) throw new Error('Gemini nÃ£o retornou transcriÃ§Ã£o');
  
  return texto.trim();
}

async function transcreverAudio(audioUrl) {
  if (!audioUrl) throw new Error('URL do Ã¡udio nÃ£o fornecida');
  
  if (STT_PROVIDER === 'gemini') {
    if (geminiApiKey) {
      try {
        console.log('ðŸŽ¤ Tentando transcriÃ§Ã£o com Gemini...');
        return await transcreverComGemini(audioUrl);
      } catch (e) {
        console.warn(`âš ï¸ Gemini falhou: ${e.message}`);
        if (openaiApiKey) {
          console.log('ðŸ”„ Tentando fallback para OpenAI...');
          const tmpFile = await downloadToTemp(audioUrl, `transcribe_${Date.now()}.webm`);
          try {
            return await transcribeWithOpenAI(tmpFile);
          } finally {
            try { await fs.unlink(tmpFile); } catch {}
          }
        }
        throw e;
      }
    } else if (openaiApiKey) {
      console.log('âš ï¸ Gemini nÃ£o configurado, usando OpenAI...');
      const tmpFile = await downloadToTemp(audioUrl, `transcribe_${Date.now()}.webm`);
      try {
        return await transcribeWithOpenAI(tmpFile);
      } finally {
        try { await fs.unlink(tmpFile); } catch {}
      }
    } else {
      throw new Error('Nem GEMINI_API_KEY nem OPENAI_API_KEY estÃ£o configurados');
    }
  } else if (STT_PROVIDER === 'openai') {
    if (openaiApiKey) {
      try {
        const tmpFile = await downloadToTemp(audioUrl, `transcribe_${Date.now()}.webm`);
        try {
          return await transcribeWithOpenAI(tmpFile);
        } finally {
          try { await fs.unlink(tmpFile); } catch {}
        }
      } catch (e) {
        console.warn(`âš ï¸ OpenAI falhou: ${e.message}`);
        if (geminiApiKey) {
          console.log('ðŸ”„ Tentando fallback para Gemini...');
          return await transcreverComGemini(audioUrl);
        }
        throw e;
      }
    } else if (geminiApiKey) {
      console.log('âš ï¸ OpenAI nÃ£o configurado, usando Gemini...');
      return await transcreverComGemini(audioUrl);
    } else {
      throw new Error('Nem OPENAI_API_KEY nem GEMINI_API_KEY estÃ£o configurados');
    }
  } else {
    throw new Error(`STT_PROVIDER nÃ£o suportado: ${STT_PROVIDER}. Use 'openai' ou 'gemini'`);
  }
}

async function atualizarTranscricao(pesquisaId, transcricao) {
  const { error } = await supabaseAdmin
    .from('pesquisas')
    .update({
      transcricao_completa: transcricao,
      stt_status: 'concluido',
      stt_erro: null,
    })
    .eq('id', pesquisaId);
  if (error) throw error;
}

// ============ FunÃ§Ãµes de IA ============
async function listGeminiModels() {
  if (!geminiApiKey) return [];
  const url = `https://generativelanguage.googleapis.com/v1/models?key=${geminiApiKey}`;
  try {
    const res = await fetch(url);
    if (!res.ok) return [];
    const data = await res.json();
    return (data?.models || []).map((m) => m.name).filter(Boolean);
  } catch {
    return [];
  }
}

function scoreModelId(id) {
  const s = String(id).toLowerCase();
  let score = 0;
  if (s.includes('flash')) score += 50;
  if (s.includes('pro')) score += 30;
  if (/(^|[-])2\.5(\.|$)/.test(s)) score += 40;
  else if (/(^|[-])2(\.|$)/.test(s)) score += 30;
  else if (/(^|[-])1\.5($|[-])/.test(s)) score += 10;
  if (s.endsWith('latest')) score += 5;
  return score;
}

async function resolveGeminiModel() {
  if (!geminiApiKey) throw new Error('GEMINI_API_KEY nÃ£o definido');
  try {
    const names = await listGeminiModels();
    const ids = names.map((n) => (typeof n === 'string' ? n.split('/').pop() || n : n));
    ids.sort((a, b) => scoreModelId(b) - scoreModelId(a));
    const best = ids[0];
    if (best) {
      console.log(`âœ“ Modelo Gemini selecionado: ${best}`);
      return best;
    }
  } catch (e) {
    console.warn('Erro ao listar modelos Gemini:', e?.message || e);
  }
  console.log('Usando modelo fallback: gemini-2.5-flash');
  return 'gemini-2.5-flash';
}

function montarPrompt(transcricao, campos, candidato) {
  const listaCampos = (campos || [])
    .map((campo) => {
      let desc = `- ${campo.id} (${campo.tipo})`;
      if (campo.label) desc += `: "${campo.label}"`;
      if (Array.isArray(campo.opcoes) && campo.opcoes.length > 0) {
        desc += ` | OpÃ§Ãµes: ${campo.opcoes.join(', ')}`;
      }
      return desc;
    })
    .join('\n');

  return `VocÃª Ã© um assistente que extrai dados estruturados de transcriÃ§Ãµes de entrevistas de pesquisa eleitoral.

**Candidato:** ${candidato || 'NÃ£o especificado'}

**Campos do formulÃ¡rio:**
${listaCampos}

**TranscriÃ§Ã£o da entrevista:**
${transcricao}

**InstruÃ§Ãµes:**
1. Leia a transcriÃ§Ã£o e identifique as respostas para cada campo
2. Para campos com opÃ§Ãµes, escolha APENAS uma das opÃ§Ãµes listadas (case-insensitive)
3. Para campos de texto livre, extraia a resposta literal
4. Se nÃ£o houver resposta clara, use null
5. Retorne um JSON vÃ¡lido no formato: { "respostas": { "campo_id": "valor", ... }, "observacoes": "texto ou null" }
6. O campo "observacoes" deve conter observaÃ§Ãµes relevantes sobre a entrevista, ou null se nÃ£o houver nada relevante a observar
7. NÃ£o adicione explicaÃ§Ãµes, apenas o JSON

**Responda agora com o JSON:**`;
}

async function processarIAComGemini(transcricao, campos, candidato, modelName) {
  if (!geminiApiKey) throw new Error('GEMINI_API_KEY ausente');
  const mdl = modelName || 'gemini-2.5-flash';
  const url = `https://generativelanguage.googleapis.com/v1/models/${encodeURIComponent(mdl)}:generateContent`;
  
  const prompt = montarPrompt(transcricao, campos, candidato);
  
  const res = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-goog-api-key': geminiApiKey,
    },
    body: JSON.stringify({
      contents: [{ role: 'user', parts: [{ text: prompt }] }]
    })
  });
  
  if (!res.ok) {
    const text = await res.text();
    throw new Error(`Gemini HTTP ${res.status}: ${text}`);
  }
  
  const data = await res.json();
  const texto = data?.candidates?.[0]?.content?.parts?.[0]?.text;
  if (!texto) throw new Error('Resposta do Gemini sem texto');
  
  let json = String(texto).trim();
  if (json.startsWith('```')) {
    json = json.replace(/```json\s*/g, '').replace(/```\s*$/g, '');
  }
  
  const jsonMatch = json.match(/\{[\s\S]*\}/);
  if (!jsonMatch) throw new Error('IA nÃ£o retornou JSON vÃ¡lido');
  
  const resultado = JSON.parse(jsonMatch[0]);
  
  // Extrair respostas e observaÃ§Ãµes
  // Pode vir como { "respostas": {...}, "observacoes": "..." } ou apenas { "campo_id": "valor" }
  let respostas = {};
  let observacoes = null;
  
  if (resultado.respostas) {
    // Formato novo: { "respostas": {...}, "observacoes": "..." }
    respostas = resultado.respostas;
    observacoes = resultado.observacoes || resultado.observacoes_ia || null;
  } else {
    // Formato antigo: { "campo_id": "valor", ... } - sem campo observacoes
    respostas = resultado;
    observacoes = null; // NÃ£o tem observaÃ§Ãµes neste formato
  }
  
  // Garantir que sempre retorna observacoes (null se nÃ£o tiver)
  return {
    respostas: respostas,
    observacoes: observacoes
  };
}

async function fetchPesquisaCompleta(pesquisaId) {
  const { data, error } = await supabaseAdmin
    .from('pesquisas')
    .select('id, formulario_id, respostas, transcricao_completa, audio_url, stt_status, stt_erro')
    .eq('id', pesquisaId)
    .single();
  if (error) throw error;
  return data;
}

async function fetchFormulario(formularioId) {
  if (!formularioId) return null;
  const { data, error } = await supabaseAdmin
    .from('formularios')
    .select('id, nome, pre_candidato, campos')
    .eq('id', formularioId)
    .single();
  if (error) throw error;
  return data;
}

async function updatePesquisaIA(pesquisaId, resultadoIA) {
  // resultadoIA pode ser { respostas: {...}, observacoes: "..." } ou apenas { campo_id: "valor" }
  const respostasIA = resultadoIA.respostas || resultadoIA;
  const observacoes = resultadoIA.observacoes || null;
  
  const { error } = await supabaseAdmin
    .from('pesquisas')
    .update({
      respostas_ia: respostasIA,
      processamento_ia_status: 'concluido',
      observacoes_ia: observacoes  // Sempre atualiza: null se nÃ£o tiver, texto se tiver
    })
    .eq('id', pesquisaId);
  if (error) throw error;
}

async function markPesquisaIAErro(pesquisaId, erro) {
  const { error } = await supabaseAdmin
    .from('pesquisas')
    .update({
      processamento_ia_status: 'erro',
      observacoes_ia: erro
    })
    .eq('id', pesquisaId);
  if (error) throw error;
}

async function fetchPesquisasPendentes() {
  // Buscar pesquisas criadas em 16-11-2025 que tenham Ã¡udio mas SEM resposta de IA concluÃ­da
  const dataInicio = '2025-11-16T00:00:00.000Z';
  const dataFim = '2025-11-16T23:59:59.999Z';
  
  // Buscar todas as pesquisas do dia com Ã¡udio
  const { data, error } = await supabaseAdmin
    .from('pesquisas')
    .select('id, audio_url, stt_status, stt_erro, processamento_ia_status, respostas_ia, formulario_id, criado_em')
    .not('audio_url', 'is', null)
    .neq('audio_url', '')
    .gte('criado_em', dataInicio)
    .lte('criado_em', dataFim)
    .order('criado_em', { ascending: true })
    .limit(100); // Buscar mais para filtrar depois
    
  if (error) {
    console.error('Erro ao buscar pesquisas:', error);
    throw error;
  }
  
  console.log(`Query executada: pesquisas criadas entre ${dataInicio} e ${dataFim}`);
  console.log(`Total encontrado no banco: ${data?.length || 0} pesquisas com Ã¡udio`);
  
  // Filtrar localmente: apenas as que NÃƒO tÃªm resposta de IA concluÃ­da
  const pesquisasFiltradas = (data || []).filter(p => {
    // Verificar se tem respostas_ia vÃ¡lidas (pode ser objeto ou string JSON)
    let temRespostaIA = false;
    if (p.respostas_ia) {
      if (typeof p.respostas_ia === 'object') {
        temRespostaIA = Object.keys(p.respostas_ia).length > 0;
      } else if (typeof p.respostas_ia === 'string') {
        try {
          const parsed = JSON.parse(p.respostas_ia);
          temRespostaIA = typeof parsed === 'object' && Object.keys(parsed).length > 0;
        } catch {
          temRespostaIA = false; // JSON invÃ¡lido = nÃ£o tem resposta vÃ¡lida
        }
      }
    }
    
    const processamentoConcluido = p.processamento_ia_status === 'concluido';
    
    // Incluir se NÃƒO tem resposta IA vÃ¡lida OU processamento nÃ£o estÃ¡ concluÃ­do
    const semRespostaIA = !temRespostaIA || !processamentoConcluido;
    
    return semRespostaIA;
  }).slice(0, BATCH_SIZE); // Limitar a 5
  
  console.log(`Filtros aplicados: sem resposta de IA concluÃ­da`);
  console.log(`Encontradas ${pesquisasFiltradas.length} pesquisas apÃ³s filtro (de ${data?.length || 0} total)`);
  
  // Debug: mostrar status das primeiras pesquisas encontradas
  if (pesquisasFiltradas.length > 0) {
    console.log(`\nPrimeiras pesquisas encontradas:`);
    pesquisasFiltradas.slice(0, 3).forEach((p, idx) => {
      console.log(`  ${idx + 1}. ID: ${p.id.substring(0, 8)}... | stt: ${p.stt_status || 'null'} | ia_status: ${p.processamento_ia_status || 'null'} | tem_respostas_ia: ${!!p.respostas_ia}`);
    });
  }
  
  return pesquisasFiltradas;
}

async function processar(pesquisa, modelName) {
  try {
    console.log(`\nðŸ“ Processando pesquisa ${pesquisa.id}...`);
    
    if (!pesquisa.audio_url) {
      console.log(`âš ï¸ Pesquisa ${pesquisa.id}: sem Ã¡udio. Pulando.`);
      return;
    }
    
    // Buscar dados completos da pesquisa e formulÃ¡rio
    const pesquisaCompleta = await fetchPesquisaCompleta(pesquisa.id);
    const formulario = await fetchFormulario(pesquisaCompleta.formulario_id);
    
    if (!formulario || !formulario.campos) {
      console.log(`âš ï¸ Pesquisa ${pesquisa.id}: sem formulÃ¡rio ou campos. Pulando.`);
      return;
    }
    
    // Atualizar status para processando
    await supabaseAdmin
      .from('pesquisas')
      .update({ stt_status: 'processando', stt_erro: null })
      .eq('id', pesquisa.id);
    
    // Transcrever Ã¡udio
    const transcricao = await transcreverAudio(pesquisa.audio_url);
    
    // Atualizar banco com transcriÃ§Ã£o
    await atualizarTranscricao(pesquisa.id, transcricao);
    
    console.log(`âœ“ TranscriÃ§Ã£o concluÃ­da para pesquisa ${pesquisa.id}`);
    console.log(`  Tamanho da transcriÃ§Ã£o: ${transcricao.length} caracteres`);
    
    // Processar com IA
    if (geminiApiKey) {
      try {
        console.log(`ðŸ¤– Processando IA para pesquisa ${pesquisa.id}...`);
        const resultadoIA = await processarIAComGemini(
          transcricao,
          formulario.campos,
          formulario.pre_candidato,
          modelName
        );
        
        await updatePesquisaIA(pesquisa.id, resultadoIA);
        const obsMsg = resultadoIA.observacoes ? ` (com observaÃ§Ãµes)` : ` (sem observaÃ§Ãµes)`;
        console.log(`âœ“ Processamento IA concluÃ­do para pesquisa ${pesquisa.id}${obsMsg}`);
      } catch (e) {
        const msg = e?.message || String(e);
        console.error(`âœ— Erro no processamento IA da pesquisa ${pesquisa.id}:`, msg);
        await markPesquisaIAErro(pesquisa.id, msg);
        // NÃ£o lanÃ§a erro aqui - a transcriÃ§Ã£o foi bem-sucedida
      }
    } else {
      console.log(`âš ï¸ GEMINI_API_KEY nÃ£o configurada. Pulando processamento IA.`);
    }
    
  } catch (e) {
    const msg = e?.message || String(e);
    console.error(`âœ— Erro na pesquisa ${pesquisa.id}:`, msg);
    
    // Marcar como erro
    await supabaseAdmin
      .from('pesquisas')
      .update({ stt_status: 'erro', stt_erro: msg })
      .eq('id', pesquisa.id);
  }
}

async function main() {
  console.log('ðŸŽ¤ Worker de TranscriÃ§Ã£o e IA iniciado...');
  console.log('Este worker transcreve e processa com IA 5 pesquisas por vez.');
  console.log('CritÃ©rios: criadas em 16-11-2025, com Ã¡udio, sem resposta de IA.');
  
  if (STT_PROVIDER === 'gemini') {
    if (!geminiApiKey) {
      console.error('âŒ GEMINI_API_KEY nÃ£o definido.');
      if (!openaiApiKey) {
        console.error('âŒ OPENAI_API_KEY tambÃ©m nÃ£o definido. Saindo.');
        process.exit(1);
      }
      console.log('âš ï¸ Usando OpenAI como fallback...');
    } else {
      console.log('ðŸŽ¤ TranscriÃ§Ã£o: Gemini (com fallback para OpenAI se necessÃ¡rio)');
    }
  } else if (STT_PROVIDER === 'openai') {
    if (!openaiApiKey) {
      console.error('âŒ OPENAI_API_KEY nÃ£o definido.');
      if (geminiApiKey) {
        console.log('âš ï¸ Usando Gemini como fallback...');
      } else {
        console.error('âŒ GEMINI_API_KEY tambÃ©m nÃ£o definido. Saindo.');
        process.exit(1);
      }
    } else {
      console.log('ðŸŽ¤ TranscriÃ§Ã£o: OpenAI');
    }
  }
  
  // Resolver modelo Gemini para IA
  let modelName = null;
  if (geminiApiKey) {
    try {
      modelName = await resolveGeminiModel();
      console.log(`ðŸ¤– Processamento IA: Gemini (modelo: ${modelName})`);
    } catch (e) {
      console.warn(`âš ï¸ NÃ£o foi possÃ­vel resolver modelo Gemini: ${e.message}`);
      console.log('âš ï¸ Processamento IA serÃ¡ pulado se Gemini nÃ£o estiver disponÃ­vel.');
    }
  } else {
    console.log('âš ï¸ GEMINI_API_KEY nÃ£o configurada. Processamento IA serÃ¡ pulado.');
  }
  
  // Loop atÃ© processar todas as pesquisas
  let totalProcessadas = 0;
  let rodada = 1;
  
  while (true) {
    console.log(`\n--- Rodada ${rodada} ---`);
    
    // Buscar pesquisas pendentes (5 por vez)
    const pesquisas = await fetchPesquisasPendentes();
    console.log(`ðŸ“Š Encontradas ${pesquisas.length} pesquisas para processar`);
    
    if (pesquisas.length === 0) {
      console.log('\nâœ“ Todas as pesquisas foram processadas!');
      console.log(`Total processado: ${totalProcessadas} pesquisas`);
      break;
    }
    
    // Processar as pesquisas desta rodada
    console.log(`ðŸ”„ Processando ${pesquisas.length} pesquisas...\n`);
    
    for (const pesquisa of pesquisas) {
      await processar(pesquisa, modelName);
      totalProcessadas++;
      // Pequeno delay entre pesquisas
      await new Promise(resolve => setTimeout(resolve, 500));
    }
    
    console.log(`âœ“ Rodada ${rodada} concluÃ­da. Processadas ${pesquisas.length} pesquisas.`);
    rodada++;
    
    // Pequeno delay entre rodadas
    await new Promise(resolve => setTimeout(resolve, 1000));
  }
  
  console.log(`\nâœ… Processamento concluÃ­do!`);
  console.log(`Total processado: ${totalProcessadas} pesquisas`);
}

main().catch(err => {
  console.error('Erro fatal:', err);
  process.exit(1);
});

